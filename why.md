I want to study ML because I think general artificial intelligence is likely to be one of the biggest drivers of change in my lifetime. Only time will tell whether that change is net positive or negative. So, I want to learn as much as I can about it so that I can leverage its benefits (currently narrow AI applications around optimization) to build things that are interesting, useful, and that people love. That will give me invaluable experience in building things for others. I want to then use that experience to try and increase the probability that AI has a positive impact on our future. I’d love to work in places like OpenAI, for example. 

The biggest excitement around ML is probably the fact that it’s finally applicable now that so much data is readily accessible. Since it’s fundamentally based on (and limited by) statistics, the more data there is, the better the performance of these models. So various specific problems can be solved using ML algorithms. Everything from image classification for diagnosing disease, to ensuring that cars drive themselves safely. All done beyond human-level performance. 

My perception of the best job opportunities is ultimately a function of my own values and preferences. A year ago that could have been trading algorithms for cryptocurrencies. Now, it’s probably around decision making and self-improvement. I think there is a plethora of useful, impactful advice for anyone that spans thousands of years. But it’s hard to personalize it. I think there might be away to bridge that gap using ML. 

Making myself employable boils down to signaling that I can create more value than I capture as an employee. Best way to do so will be to build out a portfolio of projects that showcase my technical abilities. Beyond that, it would probably be really helpful to understand what different companies look for and how to tailor my resume and interviewing towards that. Completing something like Lambda School only raises the probability that I can do so. Hence me writing this right now :)

I think that there is definitely a moral element to building things in general, and not just with ML. If I’m building something in the consumer internet for example, leveraging dopamine feedback loops to accelerate growth carries a moral cost. We’re starting to see the effects of such decisions now with things like Facebook and Instagram. Assuming that I’m proven right about the impacts of AI in the future, the weight of those decisions only increase. In other words, the depth and breadth of the impact a product or service has is proportional to how important morality has to be considered in its development. 
