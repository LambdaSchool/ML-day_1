### Why do you want to learn Machine Learning?
> There are both practical/utilitarian reasons as well as emotional reasons to want to learn ML.

> On the pragmatic side, I treat machine learning as an engine on wheels in the era of horse & carriage. If I want to explore the world, or traverse a distance, or simply carry freight, I want to do this as quickly as possible. Technology has always worked to remove redundancy and repetition from human tasks. I view Machine Learning as simply the Roomba of my future's cleaning. There are ideas I want to flesh out that I cannot do without ML. There are interests I have that will hit a ceiling of curiosity without ML solves. There are numerous direction this answer will pull all of us, but certainly, we are all looking to expedite the processes we go through each and every hour.

> More emotionally, I want to use ML to tell stories. My favorite thing about data is the ability to let data tell a narrative. Every good and full dataset can tell 100 stories, some false, some true. I want to learn these tools to tell these stories, aiming for truth. Data can inform companies on making smarter business decisions. Data can give clues into why drivers crash when they do. Data can improve human life by changing everything from medicine to stop lights to computer screens. I want to be a part of this incredible movement and buy my first Model-T.
 
### What is exciting about ML?
> The unlimited potential that lies within its ability. 

### What do you think the best job opportunities are in ML? What do you think you need to do to make yourself employable in ML?
> Most exciting would likely be entrepreneurial, but initially I would love to use ML work with big data.

### What dangers are there in studying ML?
> One simple danger could be overcomplicating your work, looking for a procedural ML path when there may be a more direct path. 

> The largest dangers I can think of are the reliance on ML before they are perfected enough to be reliable. 

> Lastly, there certainly is a limitless risks with nefarious intentions. Planting AI-driven viruses to slowly destroy networks and systems that operate river dams, electrical grids, etc. 

### Are the moral or ethical considerations that you will be responsible for?
> Of course. The oversight in this early world has the snowball potential to have horrific consequences if overlooked or left unfinished during these initial decades of setting up the world of ML. 

> There is also risk of creating, let's say, an AI that detects cancers. The risk of false-positives and false-negatives are well known from the regular way things have been done. Even if our code outperforms the rates of a doctor's false calls, we still own every mistake that AI makes. This can range from losing a company any sum of money, or losing someone's life. 
